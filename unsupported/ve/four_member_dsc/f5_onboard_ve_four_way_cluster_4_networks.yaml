# Copyright 2015 F5 Networks
# #
# # Licensed under the Apache License, Version 2.0 (the "License");
# # you may not use this file except in compliance with the License.
# # You may obtain a copy of the License at
# #
# #    http://www.apache.org/licenses/LICENSE-2.0
# #
# # Unless required by applicable law or agreed to in writing, software
# # distributed under the License is distributed on an "AS IS" BASIS,
# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# # See the License for the specific language governing permissions and
# # limitations under the License.

heat_template_version: 2014-10-16

description: >
  This template deploys a Linux image as an onboarding server for a four-way cluster of VEs with 4 nics.

parameter_groups:
- parameters: [build_network, buildserver_image, use_config_drive, package_proxy,
    http_proxy_host, http_proxy_port, http_proxy_script_url, use_proxy_for_local_resources,
    license_activation_host, license_activation_port]
- parameters: [f5_ve_os_stack_name, f5_ve_os_auth_url, f5_ve_os_tenant, f5_ve_os_user,
    f5_ve_os_password, f5_ve_os_image, f5_ve_os_flavor, f5_ve_os_config_drive, f5_ve_os_ssh_key,
    f5_odk_package_url, f5_onboard_package_url, f5_common_templates_url, f5_ve_default_gateway,
    f5_ve_admin_password, f5_ve_root_password, f5_ve_license_1, f5_ve_license_2, f5_ve_license_3,
    f5_ve_license_4]
- parameters: [f5_ve_os_external_network, f5_ve_os_mgmt_network, f5_ve_os_mgmt_network_floating_ip,
    f5_ve_os_ha_network, f5_ve_os_network_1, f5_ve_os_network_1_name, f5_ve_os_network_1_floating_ip,
    f5_ve_os_network_2, f5_ve_os_network_2_name, f5_ve_os_network_2_floating_ip, f5_ve_os_network_3,
    f5_ve_os_network_3_name, f5_ve_os_network_3_floating_ip, f5_ve_os_network_4, f5_ve_os_network_4_name,
    f5_ve_os_network_4_floating_ip]

parameters:
  build_network:
    constraints:
    - {custom_constraint: neutron.network}
    description: Network to attach the orchestration instance. Must be able to reach
      the publicURL for OS API services.
    label: F5 Onboard Server Orchestration Network
    type: string
  buildserver_image:
    constraints:
    - {custom_constraint: glance.image}
    description: Ubuntu image to use for the ochestration instance.
    label: F5 Onboard OS Image
    type: string
  f5_common_templates_url: {default: 'https://bldr-git.int.lineratesystems.com/breaux/openstack-heat-templates/raw/develop/unsupported/ve/common',
    description: The URL to download common Heat templates for F5 security groups
      and cluster topologies., label: F5 Common Template Directory URL, type: string}
  f5_odk_package_url: {default: 'https://raw.githubusercontent.com/f5openstackcommunity/f5veonboard/master/packages/odk.deb',
    description: The URL to download the ODK debian package for BIG-IP and BIG-IQ
      orchestration., label: F5 OpenStack Deployment Kit URL, type: string}
  f5_onboard_package_url: {default: 'https://raw.githubusercontent.com/f5openstackcommunity/f5veonboard/master/packages/f5_onboard.deb',
    description: The URL to download the ODK debian package for BIG-IP and BIG-IQ
      orchestration., label: F5 Virtual Edition Onboard Tools URL, type: string}
  f5_ve_admin_password:
    constraints:
    - {allowed_pattern: '[a-zA-Z0-9_-]*', description: 'Password in templates are
        limited to alpha, numeric, underscore, and dashes'}
    default: admin
    description: TMOS admin password for the VE instances.
    hidden: true
    label: F5 VE Admin User Password
    type: string
  f5_ve_default_gateway: {default: None, description: TMOS data interface upstream
      Gateway IP address., label: VE Default Gateway IP, type: string}
  f5_ve_license_1: {default: None, description: F5 TMOS license basekey for the primary
      VE instance., hidden: true, label: Primary VE License Base Key, type: string}
  f5_ve_license_2: {default: None, description: F5 TMOS license basekey for the secondary
      VE instance., hidden: true, label: Secondary VE License Base Key, type: string}
  f5_ve_license_3: {default: None, description: F5 TMOS license basekey for the third
      VE instance, hidden: true, label: Third VE License Base Key, type: string}
  f5_ve_license_4: {default: None, description: F5 TMOS license basekey for the fourth
      VE instance, hidden: true, label: Fourth VE License Base Key, type: string}
  f5_ve_os_auth_url: {description: Keystone URL to perform VE instance creation.,
    label: VE OS Keystone Auth URL, type: string}
  f5_ve_os_config_drive: {default: false, description: Use config drive to provider
      meta and user data to the VE instance., label: Use Config Drive for VE Instances,
    type: boolean}
  f5_ve_os_external_network:
    constraints:
    - {custom_constraint: neutron.network}
    description: Specify a specific Neutron external network for managment interface
      Floating IP creation.
    label: F5 VE External Network
    type: string
  f5_ve_os_flavor:
    constraints:
    - {custom_constraint: nova.flavor}
    default: m1.medium
    description: Type of instance (flavor) to be used for the VE instance.
    label: F5 VE Flavor
    type: string
  f5_ve_os_ha_network:
    constraints:
    - {custom_constraint: neutron.network}
    description: Neutron network for the VE HA config sycn and mirroring interface.
    label: F5 VE HA Network
    type: string
  f5_ve_os_image:
    constraints:
    - {custom_constraint: glance.image}
    description: The image to be used on the VE instance.
    label: F5 VE Image
    type: string
  f5_ve_os_mgmt_network:
    constraints:
    - {custom_constraint: neutron.network}
    description: Neutron network for the VE management interface.
    label: F5 VE Management Network
    type: string
  f5_ve_os_mgmt_network_floating_ip: {default: false, description: Should a Neutron
      Floating IP be created for the VE management interface., label: Create F5 VE
      Management Neutron Floating IP, type: boolean}
  f5_ve_os_network_1:
    constraints: &id001
    - {custom_constraint: neutron.network}
    description: Neutron network for the VE 1.2 data interface.
    label: F5 VE 1.2 Network
    type: string
  f5_ve_os_network_1_floating_ip: {default: false, description: Should a Floating
      SelfIP be created for the TMOS 1.2 data interface., label: Create F5 VE TMOS
      1.2 Network Floating SelfIP, type: boolean}
  f5_ve_os_network_1_name: {default: None, description: TMM network name for the untagged
      VLAN associated with the 1.2 data interface., label: F5 VE Network Name for
      the 1.2 Interface, type: string}
  f5_ve_os_network_2:
    constraints: *id001
    description: Neutron network for the VE 1.3 data interface.
    label: F5 VE 1.3 Network
    type: string
  f5_ve_os_network_2_floating_ip: {default: false, description: Should a Floating
      SelfIP be created for the TMOS 1.3 data interface., label: Create F5 VE TMOS
      1.3 Network Floating SelfIP, type: boolean}
  f5_ve_os_network_2_name: {default: None, description: TMM network name for the untagged
      VLAN associated with the 1.3 data interface., label: F5 VE Network Name for
      the 1.3 Interface, type: string}
  f5_ve_os_network_3:
    constraints: *id001
    description: Neutron network for the VE 1.4 data interface.
    label: F5 VE 1.4 Network
    type: string
  f5_ve_os_network_3_floating_ip: {default: false, description: Should a Floating
      SelfIP be created for the TMOS 1.4 data interface., label: Create F5 VE TMOS
      1.4 Network Floating SelfIP, type: boolean}
  f5_ve_os_network_3_name: {default: None, description: TMM network name for the untagged
      VLAN associated with the 1.4 data interface., label: F5 VE Network Name for
      the 1.4 Interface, type: string}
  f5_ve_os_network_4:
    constraints: *id001
    description: Neutron network for the VE 1.5 data interface.
    label: F5 VE 1.5 Network
    type: string
  f5_ve_os_network_4_floating_ip: {default: false, description: Should a Floating
      SelfIP be created for the TMOS 1.5 data interface., label: Create F5 VE TMOS
      1.5 Network Floating SelfIP, type: boolean}
  f5_ve_os_network_4_name: {default: None, description: TMM network name for the untagged
      VLAN associated with the 1.5 data interface., label: F5 VE Network Name for
      the 1.5 Interface, type: string}
  f5_ve_os_password: {default: admin, description: Password used to perform VE instance
      creation., hidden: true, label: VE OS Create User Password, type: string}
  f5_ve_os_ssh_key:
    constraints:
    - {custom_constraint: nova.keypair}
    default: None
    description: Name of key-pair to be installed for root access on the VE instances.
    label: F5 VE Root SSH Key Name
    type: string
  f5_ve_os_stack_name: {default: f5_ve_ha_1_0_1, description: Unique Name for this
      VE Device Service Group cluster., label: VE Cluster Name, type: string}
  f5_ve_os_tenant: {default: admin, description: Tenant to perform VE instance creation.,
    label: VE OS Create Tenant, type: string}
  f5_ve_os_user: {default: admin, description: User to perform VE instance creation.,
    label: VE OS Create User, type: string}
  f5_ve_root_password:
    constraints:
    - {allowed_pattern: '[a-zA-Z0-9_-]*', description: 'Password in templates are
        limited to alpha, numeric, underscore, and dashes'}
    default: admin
    description: TMOS root password for the VE instances.
    hidden: true
    label: F5 VE Root User Password
    type: string
  http_proxy_host: {default: None, label: HTTP Proxy Host to use for orchestration
      instance access, type: string}
  http_proxy_port:
    constraints:
    - range: {max: 65534, min: 1024}
    default: 8080
    label: HTTP Proxy Port to use for orchestration instance access
    type: number
  http_proxy_script_url: {default: 'https://raw.githubusercontent.com/f5openstackcommunity/f5veonboard/master/includes/f5_license_http_proxy.pl',
    description: F5 proxy script needed if HTTP proxy access is requried for VE license
      activation., label: HTTP Proxy Script URL for F5 License Client, type: string}
  license_activation_host: {default: None, description: Alternative F5 license activation
      host. Only needed if license request should not go to activate.f5.com., label: License
      Activation Host, type: string}
  license_activation_port:
    constraints:
    - range: {max: 65534, min: 1}
    default: 443
    description: Alternative F5 license activation port. Only needed if license request
      should not go to port 443.
    label: License Activation Port
    type: number
  package_proxy: {default: None, description: APT HTTP caching proxy to use for orhcestration
      package dependancies., label: Package Install Proxy URL for APT, type: string}
  use_config_drive: {default: false, description: Use config drive to provider meta
      and user data to the orchestration instance., label: Use Config Drive for Orchestration
      Server, type: boolean}
  use_proxy_for_local_resources: {default: false, description: Use the configured
      HTTP proxy when accessing OpenStack APIs., label: User HTTP proxy for OpenStack
      API Access, type: boolean}

resources:
  ve_cluster_orchestration_instance:
    properties:
      config_drive: {get_param: use_config_drive}
      flavor: m1.medium
      image: {get_param: buildserver_image}
      key_name: {get_param: f5_ve_os_ssh_key}
      networks:
      - network: {get_param: build_network}
      security_groups:
      - {get_resource: ve_cluster_orchestration_security_group}
      user_data:
        str_replace:
          params:
            __f5_common_templates_url__: {get_param: f5_common_templates_url}
            __f5_odk_package_url__: {get_param: f5_odk_package_url}
            __f5_onboard_package_url__: {get_param: f5_onboard_package_url}
            __f5_ve_admin_password__: {get_param: f5_ve_admin_password}
            __f5_ve_default_gateway__: {get_param: f5_ve_default_gateway}
            __f5_ve_license_1__: {get_param: f5_ve_license_1}
            __f5_ve_license_2__: {get_param: f5_ve_license_2}
            __f5_ve_license_3__: {get_param: f5_ve_license_3}
            __f5_ve_license_4__: {get_param: f5_ve_license_4}
            __f5_ve_os_auth_url__: {get_param: f5_ve_os_auth_url}
            __f5_ve_os_config_drive__: {get_param: f5_ve_os_config_drive}
            __f5_ve_os_external_network__: {get_param: f5_ve_os_external_network}
            __f5_ve_os_flavor__: {get_param: f5_ve_os_flavor}
            __f5_ve_os_ha_network__: {get_param: f5_ve_os_ha_network}
            __f5_ve_os_image__: {get_param: f5_ve_os_image}
            __f5_ve_os_mgmt_network__: {get_param: f5_ve_os_mgmt_network}
            __f5_ve_os_mgmt_network_floating_ip__: {get_param: f5_ve_os_mgmt_network_floating_ip}
            __f5_ve_os_network_1__: {get_param: f5_ve_os_network_1}
            __f5_ve_os_network_1_floating_ip__: {get_param: f5_ve_os_network_1_floating_ip}
            __f5_ve_os_network_1_name__: {get_param: f5_ve_os_network_1_name}
            __f5_ve_os_network_2__: {get_param: f5_ve_os_network_2}
            __f5_ve_os_network_2_floating_ip__: {get_param: f5_ve_os_network_2_floating_ip}
            __f5_ve_os_network_2_name__: {get_param: f5_ve_os_network_2_name}
            __f5_ve_os_network_3__: {get_param: f5_ve_os_network_3}
            __f5_ve_os_network_3_floating_ip__: {get_param: f5_ve_os_network_3_floating_ip}
            __f5_ve_os_network_3_name__: {get_param: f5_ve_os_network_3_name}
            __f5_ve_os_network_4__: {get_param: f5_ve_os_network_4}
            __f5_ve_os_network_4_floating_ip__: {get_param: f5_ve_os_network_4_floating_ip}
            __f5_ve_os_network_4_name__: {get_param: f5_ve_os_network_4_name}
            __f5_ve_os_password__: {get_param: f5_ve_os_password}
            __f5_ve_os_ssh_key__: {get_param: f5_ve_os_ssh_key}
            __f5_ve_os_stack_name__: {get_param: f5_ve_os_stack_name}
            __f5_ve_os_tenant__: {get_param: f5_ve_os_tenant}
            __f5_ve_os_user__: {get_param: f5_ve_os_user}
            __f5_ve_root_password__: {get_param: f5_ve_root_password}
            __http_proxy_host__: {get_param: http_proxy_host}
            __http_proxy_port__: {get_param: http_proxy_port}
            __http_proxy_script_url__: {get_param: http_proxy_script_url}
            __license_activation_host__: {get_param: license_activation_host}
            __license_activation_port__: {get_param: license_activation_port}
            __package_proxy__: {get_param: package_proxy}
            __stack_id__: {get_param: 'OS::stack_id'}
            __use_proxy_for_local_resources__: {get_param: use_proxy_for_local_resources}
          template: |
            #!/bin/bash -ex

            # create a onboard user to interactively work with this 
            # orchestration instance manual debugging
            adduser onboard --disabled-login --gecos 'Onboard' --quiet --ingroup sudo
            echo onboard:onboard|chpasswd
            sed -i 's|[#]*PasswordAuthentication no|PasswordAuthentication yes|g' /etc/ssh/sshd_config
            sed -i 's|UsePAM no|UsePAM yes|g' /etc/ssh/sshd_config
            service ssh restart
            
            # use http proxy if defined
            if [[ "__http_proxy_host__" != "None" ]]
            then
                export http_proxy=http://__http_proxy_host__:__http_proxy_port__
                export https_proxy=https://__http_proxy_host__:__http_proxy_port__
            fi
            
            if [[ "__package_proxy__" != "None" ]]
            then
                echo "Acquire::http::proxy \"__package_proxy__\";" > /etc/apt/apt.conf
                echo "Acquire::https::proxy \"__package_proxy__\";" >> /etc/apt/apt.conf
            fi
            
            # define local resource access policy
            use_proxy_for_local_resources=`echo "__use_proxy_for_local_resources__" | tr '[a-z]' '[A-Z]'`
            
            # update package list on orchestration instance
            apt-get update
            
            # get packages required for initial environment setup and global resource construction
            apt-get -y install python-keystoneclient python-novaclient python-heatclient python-neutronclient
            # export the environment which will be used in any embedded
            # orchestration process
            export HOME=/home/onboard
            export HOME=/home/onboard
            export OS_AUTH_URL=__f5_ve_os_auth_url__
            export OS_USERNAME=__f5_ve_os_user__
            export OS_PASSWORD=__f5_ve_os_password__
            export OS_TENANT_NAME=__f5_ve_os_tenant__
            export COMMON_RESOURCE_HEAT_QUERY_ATTEMPTS=100
            export COMMON_RESOUCES_HEAT_QUERY_SLEEP_INTERVAL=2
            export CLUSTER_HEAT_QUERY_ATTEMPTS=100
            export CLUSTER_HEAT_QUERY_SLEEP_INTERVAL=2
            
            # remove http proxy for local communications if not required
            if [[ $use_proxy_for_local_resources == 'FALSE' ]]
            then
                unset http_proxy
                unset https_proxy
            fi
            
            # build reference to TENANT_ID for use in queries
            export OS_TENANT_ID=`keystone tenant-get $OS_TENANT_NAME|grep id|awk -F '|' '{print $3}'|tr -d '"'|tr -d '[[:space:]]'`
            
            # work in the home directory
            cd $HOME
            
            ##########################################################################
            #
            # Common reusable resources
            #
            ##########################################################################
            
            # check the creation of common resources (can be reused between templates)
            # build these as a separate stack rather then part of the first cluster
            # stack to assure they are created before referencing them by name in your
            # cluster templates (or their nested child templates)
            BUILD_COMMONS=0
            
            commons_template_file=$HOME/f5_commons.yaml
            echo -e "heat_template_version: 2014-10-16" >$commons_template_file
            echo -e "resources:" >>$commons_template_file
            
            # common security groups nested templates
            #
            # bigip_mgmt_security_group - for the eth0 mgmt interface
            # bigip_control_security_group - for the config sync and mirror interface
            # bigip_data_security_group - wide open for additional interfaces
            #
            # The definitions of these groups can be changed in their common nested tempaltes
            #
            
            # Note: use nova .. it is tenant specific. Neutron under the admin tenant will show all tenants
            has_mgmt_group=`nova secgroup-list|grep bigip_mgmt_security_group|wc -l`
            if [[ $has_mgmt_group == 0 ]]; then
                BUILD_COMMONS=1
                echo -e "  bigip_mgmt_security_group:">>$commons_template_file
                echo -e "    type: __f5_common_templates_url__/bigip_mgmt_security_group.yaml">>$commons_template_file
            fi

            has_control_group=`nova secgroup-list|grep bigip_control_security_group|wc -l`
            if [[ $has_control_group == 0 ]]; then
                BUILD_COMMONS=1
                echo -e "  bigip_control_security_group:">>$commons_template_file
                echo -e "    type: __f5_common_templates_url__/bigip_control_security_group.yaml">>$commons_template_file
            fi
            
            has_data_group=`nova secgroup-list|grep bigip_data_security_group|wc -l`
            if [[ $has_data_group == 0 ]]; then
                BUILD_COMMONS=1
                echo -e "  bigip_data_security_group:">>$commons_template_file
                echo -e "    type: __f5_common_templates_url__/bigip_data_security_group.yaml">>$commons_template_file
            fi
            
            # If common resources required, build a heat template for them and build it
            if [[ $BUILD_COMMONS == 1 ]]
            then
               echo -e "outputs:">>$commons_template_file
               echo -e "  stack_id:">>$commons_template_file
               echo -e "    description: this stack ID">>$commons_template_file
               echo -e "    value: { get_param: \"OS::stack_id\" }">>$commons_template_file
               now=`date +%s`
               heat stack-create -f $commons_template_file -c 60 f5_common_resources_$now
               
               COMMON_RESOURCE_NOT_COMPLETE=0
               while true; do
                   # query the status of the VE image stack
                   STACK_STATUS_LINES=`heat stack-show f5_common_resources_$now|grep stack_status`
                   OIFS="$IFS"
                   IFS="|"
                   fields=($STACK_STATUS_LINES)
                   IFS="$OIFS"
                   STACK_STATUS=`echo ${fields[2]}| tr -d '[[:space:]]'`
                   STACK_STATUS_REASON=`echo ${fields[5]}| tr -d '[[:space:]]'`
                
                   echo "Common stack status is $STACK_STATUS"
                
                   if [[ $STACK_STATUS == 'CREATE_COMPLETE' ]]; then
                      echo 'Common stack are complete.'
                      break
                   fi
                   if [[ $STACK_STATUS == 'CREATE_FAILED' ]]; then
                      echo 'Common stack failed.'
                      exit
                   fi
                   sleep $COMMON_RESOUCES_HEAT_QUERY_SLEEP_INTERVAL
                   COMMON_RESOURCE_NOT_COMPLETE=$(($COMMON_RESOURCE_NOT_COMPLETE + 1))
                   if [[ $NOT_COMPLETE -ge $COMMON_RESOURCE_HEAT_QUERY_ATTEMPTS ]]; then
                       echo 'Common stack failed to reach COMPLETE before timing out'
                       exit             
                   fi
                done
                COMMON_STACK_ID=`heat output-show f5_common_resources_$now stack_id`
                COMMON_STACK_ID=`echo $COMMON_STACK_ID | tr -d '"'`
                heat stack-delete $COMMON_STACK_ID
            fi
            
            ##########################################################################
            #
            # Active / Standby Cluster dynamic template generation
            #
            ##########################################################################
                        
            # generate VE cluster template
            template_file=$HOME/f5_ve_cluster.yaml
            echo -e "heat_template_version: 2014-10-16" >$template_file
            echo -e "resources:" >>$template_file
             
            # generate VE template parameters
            p="    properties:\n"
            p="$p      ve_image: __f5_ve_os_image__ \n"
            p="$p      ve_flavor: __f5_ve_os_flavor__ \n"
            p="$p      use_config_drive: __f5_ve_os_config_drive__ \n"
            p="$p      ssh_key: __f5_ve_os_ssh_key__ \n"
            p="$p      admin_password: __f5_ve_admin_password__ \n"
            p="$p      root_password: __f5_ve_root_password__ \n"
            p="$p      http_proxy_host: __http_proxy_host__ \n"
            p="$p      http_proxy_port: __http_proxy_port__ \n"
            p="$p      http_proxy_script_url: __http_proxy_script_url__ \n"
            p="$p      license_activation_host: __license_activation_host__ \n"
            p="$p      license_activation_port: __license_activation_port__ \n"
            p="$p      mgmt_network: __f5_ve_os_mgmt_network__ \n"
            p="$p      ha_network: __f5_ve_os_ha_network__ \n"
            p="$p      default_gateway: __f5_ve_default_gateway__ \n"
            
            # if no network name was given for our data network, query neutron for the name
            NETWORK_1_NAME="__f5_ve_os_network_1_name__"
            if [[ $NETWORK_1_NAME == "None" ]]
            then
                NETWORK_1_NAME=`neutron net-list |grep __f5_ve_os_network_1__|awk -F '|' '{print $3}'| tr -d '[[:space:]]'`
            fi
            p="$p      network_1: __f5_ve_os_network_1__ \n"
            p="$p      network_1_name: $NETWORK_1_NAME\n"

            NETWORK_2_NAME="__f5_ve_os_network_2_name__"
            if [[ $NETWORK_2_NAME == "None" ]]
            then
                NETWORK_2_NAME=`neutron net-list |grep __f5_ve_os_network_2__|awk -F '|' '{print $3}'| tr -d '[[:space:]]'`
            fi
            p="$p      network_2: __f5_ve_os_network_2__ \n"
            p="$p      network_2_name: $NETWORK_2_NAME\n"
            
            #############################################
            # Add instances and licenses for four VEs
            
            # add the first VE instance resource
            echo -e "  f5_ve_instance_1:">>$template_file
            echo -e "    type: __f5_common_templates_url__/f5_ve_cluster_member_4_nic.yaml">>$template_file
            # add the first VE instance parameters
            echo -e "$p">>$template_file
            
            # add any parameters unique to the first VE
            
            # add the first VE license parameter
            echo -e "      license: __f5_ve_license_1__">>$template_file
            
            # add the second VE instance resource
            echo -e "  f5_ve_instance_2:">>$template_file
            echo -e "    type: __f5_common_templates_url__/f5_ve_cluster_member_4_nic.yaml">>$template_file
            # add the second VE instance parameters
            echo -e "$p">>$template_file
            
            # add any parameters unique to the second VE
            
            # add the second VE license parameter
            echo -e "      license: __f5_ve_license_2__">>$template_file

            # add the third VE instance resource
            echo -e "  f5_ve_instance_3:">>$template_file
            echo -e "    type: __f5_common_templates_url__/f5_ve_cluster_member_4_nic.yaml">>$template_file
            # add the third VE instance parameters
            echo -e "$p">>$template_file
            
            # add any parameters unique to the third VE
            
            # add the third VE license parameter
            echo -e "      license: __f5_ve_license_3__">>$template_file
            
            # add the fourth VE instance resource
            echo -e "  f5_ve_instance_4:">>$template_file
            echo -e "    type: __f5_common_templates_url__/f5_ve_cluster_member_4_nic.yaml">>$template_file
            # add the second VE instance parameters
            echo -e "$p">>$template_file
            
            # add any parameters unique to the fourth VE
            
            # add the second VE license parameter
            echo -e "      license: __f5_ve_license_4__">>$template_file
            
            ############################################# 
            
            # add management neutron Floating IPs resources to the template if required
            need_mgmt_floating_ip=`echo "__f5_ve_os_mgmt_network_floating_ip__" | tr '[a-z]' '[A-Z]'`
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                external_network="__f5_ve_os_external_network__"
                if [[ $external_network == "None" ]]
                then
                    nets=($(neutron net-external-list --field id |grep -v -e ^+ -e '^|[[:space:]]id'| tr -d '|'))
                    external_network=${nets[0]}
                fi
                echo -e "  f5_ve_instance_1_mgmt_floatingip:">>$template_file
                echo -e "    type: OS::Neutron::FloatingIP">>$template_file
                echo -e "    properties:">>$template_file
                echo -e "        floating_network: $external_network">>$template_file
                echo -e "        port_id: { get_attr: [f5_ve_instance_1, mgmt_port] }">>$template_file
                echo -e "  f5_ve_instance_2_mgmt_floatingip:">>$template_file
                echo -e "    type: OS::Neutron::FloatingIP">>$template_file
                echo -e "    properties:">>$template_file
                echo -e "        floating_network: $external_network">>$template_file
                echo -e "        port_id: { get_attr: [f5_ve_instance_2, mgmt_port] }">>$template_file
                echo -e "  f5_ve_instance_3_mgmt_floatingip:">>$template_file
                echo -e "    type: OS::Neutron::FloatingIP">>$template_file
                echo -e "    properties:">>$template_file
                echo -e "        floating_network: $external_network">>$template_file
                echo -e "        port_id: { get_attr: [f5_ve_instance_3, mgmt_port] }">>$template_file
                echo -e "  f5_ve_instance_4_mgmt_floatingip:">>$template_file
                echo -e "    type: OS::Neutron::FloatingIP">>$template_file
                echo -e "    properties:">>$template_file
                echo -e "        floating_network: $external_network">>$template_file
                echo -e "        port_id: { get_attr: [f5_ve_instance_4, mgmt_port] }">>$template_file
            fi
            
            # add data network ports for TMOS floating SelfIPs if required
            need_network_1_floating_ip=`echo "__f5_ve_os_network_1_floating_ip__" | tr '[a-z]' '[A-Z]'`
            if [[ $need_network_1_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_network_1_floating_selfip_port:">>$template_file
                echo -e "    type: OS::Neutron::Port">>$template_file 
                echo -e "    properties:">>$template_file
                echo -e "        network: __f5_ve_os_network_1__">>$template_file
                echo -e "        device_id: { get_attr: [f5_ve_instance_1, ve_instance_id] }">>$template_file
                echo -e "        device_owner: __f5_ve_os_stack_name__">>$template_file
            fi
            need_network_2_floating_ip=`echo "__f5_ve_os_network_2_floating_ip__" | tr '[a-z]' '[A-Z]'`
            if [[ $need_network_2_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_network_2_floating_selfip_port:">>$template_file
                echo -e "    type: OS::Neutron::Port">>$template_file 
                echo -e "    properties:">>$template_file
                echo -e "        network: __f5_ve_os_network_2__">>$template_file
                echo -e "        device_id: { get_attr: [f5_ve_instance_1, ve_instance_id] }">>$template_file
                echo -e "        device_owner: __f5_ve_os_stack_name__">>$template_file
            fi

            # create verbose outputs to provide details of the cluster for upstream
            # orchestration scripting
            echo -e "outputs:">>$template_file
            
            # first VE Nova instance information
            echo -e "  f5_ve_instance_name_1:">>$template_file
            echo -e "    description: VE 1 Nova instance name">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, ve_instance_name] }">>$template_file        
            echo -e "  f5_ve_instance_id_1:">>$template_file
            echo -e "    description: VE 1 Nova instance ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, ve_instance_id] }">>$template_file
            # first VE Neutron mgmt interface information
            echo -e "  f5_ve_mgmt_ip_1:">>$template_file
            echo -e "    description: VE 1 management IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, mgmt_ip] }">>$template_file
            echo -e "  f5_ve_mgmt_mac_1:">>$template_file
            echo -e "    description: VE 1 management MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, mgmt_mac] }">>$template_file
            echo -e "  f5_ve_mgmt_port_1:">>$template_file
            echo -e "    description: VE 1 management MAC port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, mgmt_port] }">>$template_file
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_mgmt_floatingip_ip_1:">>$template_file
                echo -e "    description: VE 1 management floatingip IP address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_instance_1_mgmt_floatingip, floating_ip_address] }">>$template_file
                echo -e "  f5_ve_mgmt_floatingip_port_1:">>$template_file
                echo -e "    description: VE 1 management floatingip ID ">>$template_file
                echo -e "    value: { get_resource: f5_ve_instance_1_mgmt_floatingip }">>$template_file
            fi
            # first VE Neutron HA interface information
            echo -e "  f5_ve_ha_ip_1:">>$template_file
            echo -e "    description: VE 1 management HA IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, ha_ip] }">>$template_file
            echo -e "  f5_ve_ha_mac_1:">>$template_file
            echo -e "    description: VE 1 management HA MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, ha_mac] }">>$template_file
            echo -e "  f5_ve_ha_port_1:">>$template_file
            echo -e "    description: VE 1 management HA port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, ha_port] }">>$template_file
            # first VE Neutron data interfaces information
            echo -e "  f5_ve_network_1_ip_1:">>$template_file
            echo -e "    description: VE 1 TMM 1.2 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, network_1_ip] }">>$template_file
            echo -e "  f5_ve_network_1_mac_1:">>$template_file
            echo -e "    description: VE 1 TMM 1.2 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, network_1_mac] }">>$template_file
            echo -e "  f5_ve_network_1_port_1:">>$template_file
            echo -e "    description: VE 1 TMM 1.2 port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, network_1_port] }">>$template_file
            # first VE Neutron data interfaces information
            echo -e "  f5_ve_network_2_ip_1:">>$template_file
            echo -e "    description: VE 1 TMM 1.3 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, network_2_ip] }">>$template_file
            echo -e "  f5_ve_network_2_mac_1:">>$template_file
            echo -e "    description: VE 1 TMM 1.3 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, network_2_mac] }">>$template_file
            echo -e "  f5_ve_network_2_port_1:">>$template_file
            echo -e "    description: VE 1 TMM 1.3 port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_1, network_2_port] }">>$template_file
            # second VE Nova instance information
            echo -e "  f5_ve_instance_name_2:">>$template_file
            echo -e "    description: VE 2 Nova instance name">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, ve_instance_name] }">>$template_file        
            echo -e "  f5_ve_instance_id_2:">>$template_file
            echo -e "    description: VE 2 Nova instance ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, ve_instance_id] }">>$template_file
            # second VE Neutron mgmt interface information
            echo -e "  f5_ve_mgmt_ip_2:">>$template_file
            echo -e "    description: VE 2 management IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, mgmt_ip] }">>$template_file
            echo -e "  f5_ve_mgmt_mac_2:">>$template_file
            echo -e "    description: VE 2 management MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, mgmt_mac] }">>$template_file
            echo -e "  f5_ve_mgmt_port_2:">>$template_file
            echo -e "    description: VE 2 management MAC port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, mgmt_port] }">>$template_file
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_mgmt_floatingip_ip_2:">>$template_file
                echo -e "    description: VE 2 management floatingip IP address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_instance_2_mgmt_floatingip, floating_ip_address] }">>$template_file
                echo -e "  f5_ve_mgmt_floatingip_port_2:">>$template_file
                echo -e "    description: VE 2 management floatingip ID ">>$template_file
                echo -e "    value: { get_resource: f5_ve_instance_2_mgmt_floatingip }">>$template_file
            fi
            # second VE Neutron HA interface information
            echo -e "  f5_ve_ha_ip_2:">>$template_file
            echo -e "    description: VE 2 management HA IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, ha_ip] }">>$template_file
            echo -e "  f5_ve_ha_mac_2:">>$template_file
            echo -e "    description: VE 2 management HA MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, ha_mac] }">>$template_file
            echo -e "  f5_ve_ha_port_2:">>$template_file
            echo -e "    description: VE 2 management HA port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, ha_port] }">>$template_file
            # second VE Neutron data interfaces information
            echo -e "  f5_ve_network_1_ip_2:">>$template_file
            echo -e "    description: VE 2 TMM 1.2 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, network_1_ip] }">>$template_file
            echo -e "  f5_ve_network_1_mac_2:">>$template_file
            echo -e "    description: VE 2 TMM 1.2 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, network_1_mac] }">>$template_file
            echo -e "  f5_ve_network_1_port_2:">>$template_file
            echo -e "    description: VE 2 TMM 1.2 port ID">>$template_file8.5GB
            echo -e "    value: { get_attr: [f5_ve_instance_2, network_1_port] }">>$template_file
            # second VE Neutron data interfaces information
            echo -e "  f5_ve_network_2_ip_2:">>$template_file
            echo -e "    description: VE 2 TMM 1.3 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, network_2_ip] }">>$template_file
            echo -e "  f5_ve_network_2_mac_2:">>$template_file
            echo -e "    description: VE 2 TMM 1.3 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_2, network_2_mac] }">>$template_file
            echo -e "  f5_ve_network_2_port_2:">>$template_file
            echo -e "    description: VE 2 TMM 1.3 port ID">>$template_file8.5GB
            echo -e "    value: { get_attr: [f5_ve_instance_2, network_2_port] }">>$template_file
            # third VE Nova instance information
            echo -e "  f5_ve_instance_name_3:">>$template_file
            echo -e "    description: VE 3 Nova instance name">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, ve_instance_name] }">>$template_file        
            echo -e "  f5_ve_instance_id_3:">>$template_file
            echo -e "    description: VE 3 Nova instance ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, ve_instance_id] }">>$template_file
            # third VE Neutron mgmt interface information
            echo -e "  f5_ve_mgmt_ip_3:">>$template_file
            echo -e "    description: VE 3 management IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, mgmt_ip] }">>$template_file
            echo -e "  f5_ve_mgmt_mac_3:">>$template_file
            echo -e "    description: VE 3 management MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, mgmt_mac] }">>$template_file
            echo -e "  f5_ve_mgmt_port_3:">>$template_file
            echo -e "    description: VE 3 management MAC port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, mgmt_port] }">>$template_file
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_mgmt_floatingip_ip_3:">>$template_file
                echo -e "    description: VE 3 management floatingip IP address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_instance_3_mgmt_floatingip, floating_ip_address] }">>$template_file
                echo -e "  f5_ve_mgmt_floatingip_port_3:">>$template_file
                echo -e "    description: VE 3 management floatingip ID ">>$template_file
                echo -e "    value: { get_resource: f5_ve_instance_3_mgmt_floatingip }">>$template_file
            fi
            # third VE Neutron HA interface information
            echo -e "  f5_ve_ha_ip_3:">>$template_file
            echo -e "    description: VE 3 management HA IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, ha_ip] }">>$template_file
            echo -e "  f5_ve_ha_mac_3:">>$template_file
            echo -e "    description: VE 3 management HA MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, ha_mac] }">>$template_file
            echo -e "  f5_ve_ha_port_3:">>$template_file
            echo -e "    description: VE 3 management HA port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, ha_port] }">>$template_file
            # third VE Neutron data interfaces information
            echo -e "  f5_ve_network_1_ip_3:">>$template_file
            echo -e "    description: VE 3 TMM 1.2 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, network_1_ip] }">>$template_file
            echo -e "  f5_ve_network_1_mac_3:">>$template_file
            echo -e "    description: VE 3 TMM 1.2 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, network_1_mac] }">>$template_file
            echo -e "  f5_ve_network_1_port_3:">>$template_file
            echo -e "    description: VE 3 TMM 1.2 port ID">>$template_file8.5GB
            echo -e "    value: { get_attr: [f5_ve_instance_3, network_1_port] }">>$template_file
            # third VE Neutron data interfaces information
            echo -e "  f5_ve_network_2_ip_3:">>$template_file
            echo -e "    description: VE 3 TMM 1.3 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, network_2_ip] }">>$template_file
            echo -e "  f5_ve_network_2_mac_3:">>$template_file
            echo -e "    description: VE 3 TMM 1.3 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_3, network_2_mac] }">>$template_file
            echo -e "  f5_ve_network_2_port_3:">>$template_file
            echo -e "    description: VE 3 TMM 1.3 port ID">>$template_file8.5GB
            echo -e "    value: { get_attr: [f5_ve_instance_3, network_2_port] }">>$template_file
            # fourth VE Nova instance information
            echo -e "  f5_ve_instance_name_4:">>$template_file
            echo -e "    description: VE 4 Nova instance name">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, ve_instance_name] }">>$template_file        
            echo -e "  f5_ve_instance_id_4:">>$template_file
            echo -e "    description: VE 4 Nova instance ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, ve_instance_id] }">>$template_file
            # fourth VE Neutron mgmt interface information
            echo -e "  f5_ve_mgmt_ip_4:">>$template_file
            echo -e "    description: VE 4 management IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, mgmt_ip] }">>$template_file
            echo -e "  f5_ve_mgmt_mac_4:">>$template_file
            echo -e "    description: VE 4 management MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, mgmt_mac] }">>$template_file
            echo -e "  f5_ve_mgmt_port_4:">>$template_file
            echo -e "    description: VE 4 management MAC port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, mgmt_port] }">>$template_file
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_mgmt_floatingip_ip_4:">>$template_file
                echo -e "    description: VE 4 management floatingip IP address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_instance_4_mgmt_floatingip, floating_ip_address] }">>$template_file
                echo -e "  f5_ve_mgmt_floatingip_port_4:">>$template_file
                echo -e "    description: VE 4 management floatingip ID ">>$template_file
                echo -e "    value: { get_resource: f5_ve_instance_4_mgmt_floatingip }">>$template_file
            fi
            # fourth VE Neutron HA interface information
            echo -e "  f5_ve_ha_ip_4:">>$template_file
            echo -e "    description: VE 4 management HA IP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, ha_ip] }">>$template_file
            echo -e "  f5_ve_ha_mac_4:">>$template_file
            echo -e "    description: VE 4 management HA MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, ha_mac] }">>$template_file
            echo -e "  f5_ve_ha_port_4:">>$template_file
            echo -e "    description: VE 4 management HA port ID">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, ha_port] }">>$template_file
            # fourth VE Neutron data interfaces information
            echo -e "  f5_ve_network_1_ip_4:">>$template_file
            echo -e "    description: VE 4 TMM 1.2 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, network_1_ip] }">>$template_file
            echo -e "  f5_ve_network_1_mac_4:">>$template_file
            echo -e "    description: VE 4 TMM 1.2 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, network_1_mac] }">>$template_file
            echo -e "  f5_ve_network_1_port_4:">>$template_file
            echo -e "    description: VE 4 TMM 1.2 port ID">>$template_file8.5GB
            echo -e "    value: { get_attr: [f5_ve_instance_4, network_1_port] }">>$template_file
            # fourth VE Neutron data interfaces information
            echo -e "  f5_ve_network_2_ip_4:">>$template_file
            echo -e "    description: VE 4 TMM 1.3 non floating SelfIP address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, network_2_ip] }">>$template_file
            echo -e "  f5_ve_network_2_mac_4:">>$template_file
            echo -e "    description: VE 4 TMM 1.3 MAC address">>$template_file
            echo -e "    value: { get_attr: [f5_ve_instance_4, network_2_mac] }">>$template_file
            echo -e "  f5_ve_network_2_port_4:">>$template_file
            echo -e "    description: VE 4 TMM 1.3 port ID">>$template_file8.5GB
            echo -e "    value: { get_attr: [f5_ve_instance_4, network_2_port] }">>$template_file

            # VE Neutron data for floating SelfIP address
            if [[ $need_network_1_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_network_1_floating_selfip_ip:">>$template_file
                echo -e "    description: TMM 1.2 Floating SelfIP address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_network_1_floating_selfip_port, fixed_ips, 0, ip_address] }">>$template_file
                echo -e "  f5_ve_network_1_floating_selfip_subnet_id:">>$template_file
                echo -e "    description: TMM 1.2 Floating SelfIP Subnet ID">>$template_file
                echo -e "    value: { get_attr: [f5_ve_network_1_floating_selfip_port, fixed_ips, 0, subnet_id] }">>$template_file
                echo -e "  f5_ve_network_1_floating_selfip_mac:">>$template_file
                echo -e "    description: TMM 1.2 Floating SelfIP port MAC address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_network_1_floating_selfip_port, mac_address] }">>$template_file
                echo -e "  f5_ve_network_1_floating_selfip_port:">>$template_file
                echo -e "    description: TMM 1.2 Floating SelfIP port ID">>$template_file
                echo -e "    value: { get_resource: f5_ve_network_1_floating_selfip_port }">>$template_file
            fi
            
            if [[ $need_network_2_floating_ip == 'TRUE' ]]
            then
                echo -e "  f5_ve_network_2_floating_selfip_ip:">>$template_file
                echo -e "    description: TMM 1.3 Floating SelfIP address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_network_2_floating_selfip_port, fixed_ips, 0, ip_address] }">>$template_file
                echo -e "  f5_ve_network_2_floating_selfip_subnet_id:">>$template_file
                echo -e "    description: TMM 1.3 Floating SelfIP Subnet ID">>$template_file
                echo -e "    value: { get_attr: [f5_ve_network_2_floating_selfip_port, fixed_ips, 0, subnet_id] }">>$template_file
                echo -e "  f5_ve_network_2_floating_selfip_mac:">>$template_file
                echo -e "    description: TMM 1.3 Floating SelfIP port MAC address">>$template_file
                echo -e "    value: { get_attr: [f5_ve_network_2_floating_selfip_port, mac_address] }">>$template_file
                echo -e "  f5_ve_network_2_floating_selfip_port:">>$template_file
                echo -e "    description: TMM 1.3 Floating SelfIP port ID">>$template_file
                echo -e "    value: { get_resource: f5_ve_network_2_floating_selfip_port }">>$template_file
            fi
            
            # display template to console output
            echo "Generated template is:"
            cat $template_file
            echo "End of template"
            
            # display stack id to console output
            echo "My stack id is:" __stack_id__
            
            # build VE cluster instances stack
            heat stack-create -f $template_file -c 60 __f5_ve_os_stack_name__
            
            # wait for VE cluster instances stack to complete
            CLUSTER_HEAT_NOT_COMPLETE=0
            while true; do
                # query the status of the VE image stack
                STACK_STATUS_LINES=`heat stack-show __f5_ve_os_stack_name__|grep stack_status`
                OIFS="$IFS"
                IFS="|"
                fields=($STACK_STATUS_LINES)
                IFS="$OIFS"
                STACK_STATUS=`echo ${fields[2]}| tr -d '[[:space:]]'`
                STACK_STATUS_REASON=`echo ${fields[5]}| tr -d '[[:space:]]'`
                
                echo "Stack status is $STACK_STATUS"
                
                if [[ $STACK_STATUS == 'CREATE_COMPLETE' ]]; then
                    echo 'VE HA instances are complete. Clustering instances..'
                    break
                fi
                if [[ $STACK_STATUS == 'CREATE_FAILED' ]]; then
                    echo 'VE HA instances failed.'
                    wc_notify --data-binary '{"status": "FAILURE", "reason": "VE HA instance template failed." }'
                    exit
                fi
                sleep $CLUSTER_HEAT_QUERY_SLEEP_INTERVAL
                CLUSTER_HEAT_NOT_COMPLETE=$(($CLUSTER_HEAT_NOT_COMPLETE + 1))
                if [[ $CLUSTER_HEAT_NOT_COMPLETE -ge $CLUSTER_HEAT_QUERY_ATTEMPTS ]]; then
                    echo 'VE HA stack failed to reach COMPLETE before timing out'
                    wc_notify --data-binary '{"status": "FAILURE", "reason": "VE HA instance failed to reach COMPLETE before timing out." }'
                    exit             
                fi
            done
            
            # add Neutron allowed address pairs for floating selfIPs
            if [[ $need_network_1_floating_ip == 'TRUE' ]]
            then
               NETWORK_1_FLOATING_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_floating_selfip_ip`
               NETWORK_1_FLOATING_IP=`echo $NETWORK_1_FLOATING_IP | tr -d '"'`
               NETWORK_1_FLOATING_IP_SUBNET_ID=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_floating_selfip_subnet_id`
               NETWORK_1_FLOATING_IP_SUBNET_ID=`echo $NETWORK_1_FLOATING_IP_SUBNET_ID | tr -d '"'`
               NETWORK_1_FLOATING_CIDR=`neutron subnet-show $NETWORK_1_FLOATING_IP_SUBNET_ID|grep cidr|awk -F '|' '{print $3}'`
               NETWORK_1_FLOATING_CIDR=`echo $NETWORK_1_FLOATING_CIDR | tr -d '"'`

               VE1_NETWORK_1_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_port_1`
               VE1_NETWORK_1_PORT=`echo $VE1_NETWORK_1_PORT | tr -d '"'`
               neutron port-update $VE1_NETWORK_1_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_1_FLOATING_IP
               VE2_NETWORK_1_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_port_2`
               VE2_NETWORK_1_PORT=`echo $VE2_NETWORK_1_PORT | tr -d '"'`
               neutron port-update $VE2_NETWORK_1_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_1_FLOATING_IP
               VE3_NETWORK_1_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_port_3`
               VE3_NETWORK_1_PORT=`echo $VE3_NETWORK_1_PORT | tr -d '"'`
               neutron port-update $VE3_NETWORK_1_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_1_FLOATING_IP
               VE4_NETWORK_1_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_port_4`
               VE4_NETWORK_1_PORT=`echo $VE4_NETWORK_1_PORT | tr -d '"'`
               neutron port-update $VE4_NETWORK_1_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_1_FLOATING_IP
            fi

            if [[ $need_network_2_floating_ip == 'TRUE' ]]
            then
               NETWORK_2_FLOATING_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_floating_selfip_ip`
               NETWORK_2_FLOATING_IP=`echo $NETWORK_2_FLOATING_IP | tr -d '"'`
               NETWORK_2_FLOATING_IP_SUBNET_ID=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_floating_selfip_subnet_id`
               NETWORK_2_FLOATING_IP_SUBNET_ID=`echo $NETWORK_2_FLOATING_IP_SUBNET_ID | tr -d '"'`
               NETWORK_2_FLOATING_CIDR=`neutron subnet-show $NETWORK_2_FLOATING_IP_SUBNET_ID|grep cidr|awk -F '|' '{print $3}'`
               NETWORK_2_FLOATING_CIDR=`echo $NETWORK_2_FLOATING_CIDR | tr -d '"'`

               VE1_NETWORK_2_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_port_1`
               VE1_NETWORK_2_PORT=`echo $VE1_NETWORK_2_PORT | tr -d '"'`
               neutron port-update $VE1_NETWORK_2_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_2_FLOATING_IP
               VE2_NETWORK_2_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_port_2`
               VE2_NETWORK_2_PORT=`echo $VE2_NETWORK_2_PORT | tr -d '"'`
               neutron port-update $VE2_NETWORK_2_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_2_FLOATING_IP
               VE3_NETWORK_2_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_port_3`
               VE3_NETWORK_2_PORT=`echo $VE3_NETWORK_2_PORT | tr -d '"'`
               neutron port-update $VE3_NETWORK_2_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_2_FLOATING_IP
               VE4_NETWORK_2_PORT=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_port_4`
               VE4_NETWORK_2_PORT=`echo $VE4_NETWORK_2_PORT | tr -d '"'`
               neutron port-update $VE4_NETWORK_2_PORT --allowed_address_pairs list=true type=dict ip_address=$NETWORK_2_FLOATING_IP
            fi
   
            # query heat VE instance stack for the assigned IP addresses to cluster the VEs
            VE1_MGMT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_ip_1`
            VE1_MGMT_IP=`echo $VE1_MGMT_IP | tr -d '"'`
            VE1_MGMT_FLOAT_IP=$VE1_MGMT_IP
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                VE1_MGMT_FLOAT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_floatingip_ip_1`
                VE1_MGMT_FLOAT_IP=`echo $VE1_MGMT_FLOAT_IP | tr -d '"'`
            fi
            VE1_HA_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_ha_ip_1`
            VE1_HA_IP=`echo $VE1_HA_IP | tr -d '"'`
            VE2_MGMT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_ip_2`
            VE2_MGMT_IP=`echo $VE2_MGMT_IP | tr -d '"'`
            VE2_MGMT_FLOAT_IP=$VE2_MGMT_IP
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                VE2_MGMT_FLOAT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_floatingip_ip_2`
                VE2_MGMT_FLOAT_IP=`echo $VE2_MGMT_FLOAT_IP | tr -d '"'`
            fi
            VE2_HA_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_ha_ip_2`
            VE2_HA_IP=`echo $VE2_HA_IP | tr -d '"'`

            VE3_MGMT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_ip_3`
            VE3_MGMT_IP=`echo $VE3_MGMT_IP | tr -d '"'`
            VE3_MGMT_FLOAT_IP=$VE3_MGMT_IP
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                VE3_MGMT_FLOAT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_floatingip_ip_3`
                VE3_MGMT_FLOAT_IP=`echo $VE3_MGMT_FLOAT_IP | tr -d '"'`
            fi
            VE3_HA_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_ha_ip_3`
            VE3_HA_IP=`echo $VE3_HA_IP | tr -d '"'`
            VE4_MGMT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_ip_4`
            VE4_MGMT_IP=`echo $VE4_MGMT_IP | tr -d '"'`
            VE4_MGMT_FLOAT_IP=$VE4_MGMT_IP
            if [[ $need_mgmt_floating_ip == 'TRUE' ]]
            then
                VE4_MGMT_FLOAT_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_mgmt_floatingip_ip_4`
                VE4_MGMT_FLOAT_IP=`echo $VE4_MGMT_FLOAT_IP | tr -d '"'`
            fi
            VE4_HA_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_ha_ip_4`
            VE4_HA_IP=`echo $VE4_HA_IP | tr -d '"'`

            # use http proxy if defined
            if [[ "__http_proxy_host__" != "None" ]]
            then
                export http_proxy=http://__http_proxy_host__:__http_proxy_port__
                export https_proxy=https://__http_proxy_host__:__http_proxy_port__
            fi
            
            # Download provisioning agent packages
            wget -q -c -nc -O /home/onboard/odk.deb __f5_odk_package_url__
            wget -q -c -nc -O /home/onboard/f5_onboard.deb __f5_onboard_package_url__

            # Install any dependancies for agent package work
            apt-get -y install unzip qemu-utils lvm2 python-keystoneclient python-glanceclient python-novaclient python-cinderclient python-eventlet python-suds python-paramiko
            
            # install packages
            dpkg -i /home/onboard/odk.deb
            dpkg -i /home/onboard/f5_onboard.deb    
            
            # remove http proxy for local communications if not required
            if [[ $use_proxy_for_local_resources == 'FALSE' ]]
            then
                unset http_proxy
                unset https_proxy
            fi
            
            # TODO: These wgets are just patches to cluster.py and cluster_generic.py until we have redeployable packages of the refactored odk/onboard/common code.
            wget --no-check-certificate -O /usr/lib/python2.7/dist-packages/f5/bigip/interfaces/cluster.py https://bldr-git.int.lineratesystems.com/breaux/f5-common-python-local/raw/develop_breaux_four-way-cluster/f5/bigip/interfaces/cluster.py

            wget --no-check-certificate -O /usr/lib/python2.7/dist-packages/f5/onboard/bigip/cluster_generic.py https://bldr-git.int.lineratesystems.com/breaux/f5-openstack-onboard-local/raw/onboard_breaux_no_failover/f5_onboarding/cluster_generic.py

            # cluster VEs
            # cluster tenant stacked BIG-IPS
            source f5-onboard-utils

            python $F5_ONBOARD_BIGIP_PY_DIR/cluster_generic.py \
            --ha-type scalen --num-bigips 4 --no-tgs \
            --bigip-floating-ip-addr-list $VE1_MGMT_FLOAT_IP $VE2_MGMT_FLOAT_IP $VE3_MGMT_FLOAT_IP $VE4_MGMT_FLOAT_IP \
            --bigip-mgmt-addr-list $VE1_MGMT_IP $VE2_MGMT_IP $VE3_MGMT_IP $VE4_MGMT_IP \
            --bigip-ha-addr-list $VE1_HA_IP $VE2_HA_IP $VE3_HA_IP $VE4_HA_IP \
            --bigip-mirror-addr-list $VE1_HA_IP $VE2_HA_IP $VE3_HA_IP $VE4_HA_IP \
            --bigip-cluster-name __f5_ve_os_stack_name__ \
            --bigip-icontrol-username admin \
            --bigip-icontrol-password __f5_ve_admin_password__
            
            # if TMOS floating SelfIPs are defined, create them and sync to cluster
            if [[ $need_network_1_floating_ip == 'TRUE' ]]
            then
               NETWORK_1_FLOATING_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_1_floating_selfip_ip`
               NETWORK_1_FLOATING_IP=`echo $NETWORK_1_FLOATING_IP | tr -d '"'`
               python $F5_ONBOARD_BIGIP_PY_DIR/add_floating_self_ips.py \
                --network-list $NETWORK_1_NAME \
                --selfip-list $NETWORK_1_FLOATING_IP \
                --cidr-list $NETWORK_1_FLOATING_CIDR \
                --access-list all \
                --bigip-icontrol-host $VE1_MGMT_FLOAT_IP \
                --bigip-icontrol-username admin \
                --bigip-icontrol-password __f5_ve_admin_password__
            fi

            if [[ $need_network_2_floating_ip == 'TRUE' ]]
            then
               NETWORK_2_FLOATING_IP=`heat output-show __f5_ve_os_stack_name__ f5_ve_network_2_floating_selfip_ip`
               NETWORK_2_FLOATING_IP=`echo $NETWORK_2_FLOATING_IP | tr -d '"'`
               python $F5_ONBOARD_BIGIP_PY_DIR/add_floating_self_ips.py \
                --network-list $NETWORK_2_NAME \
                --selfip-list $NETWORK_2_FLOATING_IP \
                --cidr-list $NETWORK_2_FLOATING_CIDR \
                --access-list all \
                --bigip-icontrol-host $VE1_MGMT_FLOAT_IP \
                --bigip-icontrol-username admin \
                --bigip-icontrol-password __f5_ve_admin_password__
            fi
            
            # delete this orchestration stack
            heat stack-delete __stack_id__
      user_data_format: RAW
    type: OS::Nova::Server
  ve_cluster_orchestration_security_group:
    properties:
      name: onboard_security_group
      rules:
      - {direction: ingress, protocol: icmp}
      - {direction: egress, protocol: icmp}
      - {direction: ingress, protocol: tcp}
      - {direction: egress, protocol: tcp}
      - {direction: ingress, protocol: udp}
      - {direction: egress, protocol: udp}
    type: OS::Neutron::SecurityGroup
  wait_condition:
    properties:
      count: 1
      handle: {get_resource: wait_handle}
      timeout: 3600
    type: OS::Heat::WaitCondition
  wait_handle: {type: 'OS::Heat::WaitConditionHandle'}
